# Prometheus Metrics Design for Manatee CMON Integration

This document was generated by Claude Code as part of the analysis leading into this work.

## Overview

This document describes the design for exposing Prometheus-style cluster health metrics from Manatee to enable CMON monitoring of all Manatee clusters.

## Current State Analysis

### Existing Monitoring Infrastructure

Manatee already has comprehensive cluster monitoring through `manatee-adm pg-status` command, which uses the `loadClusterDetails` function in `/workspace/manatee/manatee/lib/adm.js:652`.

This function provides:
- Peer status and replication state
- Cluster generation and WAL information  
- Primary/sync/async peer identification
- Error and warning conditions
- Frozen state detection
- PostgreSQL connectivity status

### Current Status Server

Manatee includes a status server (`lib/statusServer.js`) that already exposes:
- `/ping` - Health check endpoint
- `/` - Basic status information

## Proposed Solution

### 1. HTTP Metrics Endpoint

Add a new `/metrics` endpoint to the existing status server that returns Prometheus-formatted metrics.

#### Implementation Location
- **File**: `/workspace/manatee/manatee/lib/statusServer.js`
- **New endpoint**: `GET /metrics`
- **Response format**: Prometheus text format

#### Code Structure
```javascript
// Add to statusServer.js
server.get('/metrics', function handleMetrics(req, res, next) {
    var clusterArgs = {
        shard: config.shardPath,
        zk: config.zk.connectString,
        skipPostgres: false
    };
    
    loadClusterDetails(clusterArgs, function (err, details) {
        if (err) {
            res.send(500, formatPrometheusError(err));
            return next();
        }
        
        var metrics = formatPrometheusMetrics(details, config);
        res.setHeader('Content-Type', 'text/plain; version=0.0.4; charset=utf-8');
        res.send(200, metrics);
        return next();
    });
});
```

### 2. Prometheus Metrics Format

#### Core Cluster Metrics

```prometheus
# HELP manatee_cluster_peers_total Total number of peers in the cluster
# TYPE manatee_cluster_peers_total gauge
manatee_cluster_peers_total{shard="1.moray.emy-10.joyent.us"} 3

# HELP manatee_cluster_generation Current cluster generation number
# TYPE manatee_cluster_generation gauge
manatee_cluster_generation{shard="1.moray.emy-10.joyent.us"} 42

# HELP manatee_cluster_frozen Cluster frozen state (1=frozen, 0=active)
# TYPE manatee_cluster_frozen gauge
manatee_cluster_frozen{shard="1.moray.emy-10.joyent.us"} 0

# HELP manatee_cluster_singleton Cluster singleton mode (1=singleton, 0=normal)
# TYPE manatee_cluster_singleton gauge
manatee_cluster_singleton{shard="1.moray.emy-10.joyent.us"} 0

# HELP manatee_cluster_errors_total Count of cluster-level errors
# TYPE manatee_cluster_errors_total gauge
manatee_cluster_errors_total{shard="1.moray.emy-10.joyent.us"} 0

# HELP manatee_cluster_warnings_total Count of cluster-level warnings
# TYPE manatee_cluster_warnings_total gauge
manatee_cluster_warnings_total{shard="1.moray.emy-10.joyent.us"} 0
```

#### Peer-Specific Metrics

```prometheus
# HELP manatee_peer_postgres_up PostgreSQL connectivity (1=up, 0=down)
# TYPE manatee_peer_postgres_up gauge
manatee_peer_postgres_up{shard="1.moray.emy-10.joyent.us",peer="primary",role="primary"} 1
manatee_peer_postgres_up{shard="1.moray.emy-10.joyent.us",peer="sync",role="sync"} 1
manatee_peer_postgres_up{shard="1.moray.emy-10.joyent.us",peer="async",role="async"} 1

# HELP manatee_peer_replication_lag_seconds Replication lag in seconds
# TYPE manatee_peer_replication_lag_seconds gauge
manatee_peer_replication_lag_seconds{shard="1.moray.emy-10.joyent.us",peer="primary",role="primary"} 0
manatee_peer_replication_lag_seconds{shard="1.moray.emy-10.joyent.us",peer="sync",role="sync"} 0.1
manatee_peer_replication_lag_seconds{shard="1.moray.emy-10.joyent.us",peer="async",role="async"} 0.3

# HELP manatee_peer_replication_state Replication connection state (1=streaming, 0=disconnected)
# TYPE manatee_peer_replication_state gauge
manatee_peer_replication_state{shard="1.moray.emy-10.joyent.us",peer="sync",role="sync"} 1
manatee_peer_replication_state{shard="1.moray.emy-10.joyent.us",peer="async",role="async"} 1

# HELP manatee_peer_wal_position Current WAL position
# TYPE manatee_peer_wal_position gauge
manatee_peer_wal_position{shard="1.moray.emy-10.joyent.us",peer="primary",role="primary"} 25165824
```

### 3. Metrics Formatter Implementation

#### New Module: `lib/prometheusFormatter.js`

```javascript
/**
 * Format cluster details as Prometheus metrics
 */
function formatPrometheusMetrics(clusterDetails, config) {
    var lines = [];
    var shard = config.shardPath;
    
    // Cluster-level metrics
    addClusterMetrics(lines, clusterDetails, shard);
    
    // Peer-level metrics
    addPeerMetrics(lines, clusterDetails, shard);
    
    return lines.join('\n') + '\n';
}

function addClusterMetrics(lines, details, shard) {
    // Total peers
    var peerCount = Object.keys(details.pgs_peers || {}).length;
    addMetric(lines, 'manatee_cluster_peers_total', peerCount, {shard: shard});
    
    // Generation
    if (details.pgs_generation !== undefined) {
        addMetric(lines, 'manatee_cluster_generation', details.pgs_generation, {shard: shard});
    }
    
    // Frozen state
    addMetric(lines, 'manatee_cluster_frozen', details.pgs_frozen ? 1 : 0, {shard: shard});
    
    // Singleton mode
    addMetric(lines, 'manatee_cluster_singleton', details.pgs_singleton ? 1 : 0, {shard: shard});
    
    // Error and warning counts
    addMetric(lines, 'manatee_cluster_errors_total', (details.pgs_errors || []).length, {shard: shard});
    addMetric(lines, 'manatee_cluster_warnings_total', (details.pgs_warnings || []).length, {shard: shard});
}

function addPeerMetrics(lines, details, shard) {
    var peers = details.pgs_peers || {};
    
    Object.keys(peers).forEach(function (peerId) {
        var peer = peers[peerId];
        var role = getPeerRole(peerId, details);
        var labels = {
            shard: shard,
            peer: peerId,
            role: role
        };
        
        // PostgreSQL connectivity
        var pgUp = peer.pgp_pgerr ? 0 : 1;
        addMetric(lines, 'manatee_peer_postgres_up', pgUp, labels);
        
        // Replication lag
        if (peer.pgp_lag !== undefined) {
            var lagSeconds = Math.round(peer.pgp_lag / 1000);
            addMetric(lines, 'manatee_peer_replication_lag_seconds', lagSeconds, labels);
        }
        
        // Replication state
        if (peer.pgp_repl) {
            var replState = peer.pgp_repl.state === 'streaming' ? 1 : 0;
            addMetric(lines, 'manatee_peer_replication_state', replState, labels);
        }
    });
}

function addMetric(lines, name, value, labels) {
    var labelStr = Object.keys(labels)
        .map(k => k + '="' + labels[k] + '"')
        .join(',');
    
    lines.push(name + '{' + labelStr + '} ' + value);
}

function getPeerRole(peerId, details) {
    if (peerId === details.pgs_primary) return 'primary';
    if (peerId === details.pgs_sync) return 'sync';
    if ((details.pgs_asyncs || []).includes(peerId)) return 'async';
    return 'unknown';
}
```

### 4. Configuration Integration

#### Status Server Configuration

The metrics endpoint should be enabled by default but configurable:

```json
{
    "statusServer": {
        "port": 8080,
        "metrics": {
            "enabled": true,
            "endpoint": "/metrics"
        }
    }
}
```

### 5. CMON Integration

#### Scrape Configuration

CMON should be configured to scrape all Manatee instances:

```yaml
# CMON scrape configuration
scrape_configs:
  - job_name: 'manatee'
    scrape_interval: 30s
    metrics_path: /metrics
    static_configs:
      - targets:
        - manatee-primary:8080
        - manatee-sync:8080
        - manatee-async:8080
    # Or use service discovery
    triton_sd_configs:
      - account: "admin"
        dns_suffix: "cns.joyent.com"
        endpoint: "https://us-east-1.api.joyent.com"
        services: ["manatee"]
```

#### Service Discovery

For dynamic discovery, use SAPI metadata:

```javascript
// Service discovery helper
function discoverManateeInstances() {
    // Query SAPI for manatee services
    // Return list of {host, port, shard} objects
}
```

### 6. Alerting Rules

#### Critical Alerts

```yaml
groups:
  - name: manatee.rules
    rules:
      - alert: ManateeClusterFrozen
        expr: manatee_cluster_frozen == 1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Manatee cluster {{ $labels.shard }} is frozen"

      - alert: ManateePostgresDown
        expr: manatee_peer_postgres_up == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL down on {{ $labels.peer }} ({{ $labels.role }})"

      - alert: ManateeHighReplicationLag
        expr: manatee_peer_replication_lag_seconds > 30
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High replication lag on {{ $labels.peer }}: {{ $value }}s"

      - alert: ManateeClusterErrors
        expr: manatee_cluster_errors_total > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Manatee cluster {{ $labels.shard }} has {{ $value }} errors"
```

## Implementation Plan

### Phase 1: Core Implementation
1. **Add metrics endpoint** to statusServer.js
2. **Create prometheus formatter** module
3. **Test with sample cluster** data
4. **Validate Prometheus format** compliance

### Phase 2: Integration Testing  
1. **Deploy to development** environment
2. **Configure CMON scraping**
3. **Test alert rules**
4. **Validate dashboards**

### Phase 3: Production Rollout
1. **Deploy to staging** environments
2. **Monitor for performance** impact
3. **Gradual production** deployment
4. **Monitor and tune** scrape intervals

## Performance Considerations

### Impact Analysis
- `/metrics` endpoint uses existing `loadClusterDetails` function
- ZooKeeper queries and PostgreSQL connections already optimized
- Response size: ~1-2KB for typical 3-node cluster
- Recommended scrape interval: 30-60 seconds

### Caching Strategy
Consider adding response caching if scrape frequency becomes high:

```javascript
var metricsCache = {
    data: null,
    timestamp: 0,
    ttl: 10000  // 10 seconds
};

function getCachedMetrics(callback) {
    var now = Date.now();
    if (metricsCache.data && (now - metricsCache.timestamp) < metricsCache.ttl) {
        return callback(null, metricsCache.data);
    }
    
    // Refresh cache
    loadClusterDetails(args, function (err, details) {
        if (!err) {
            metricsCache.data = formatPrometheusMetrics(details);
            metricsCache.timestamp = now;
        }
        callback(err, metricsCache.data);
    });
}
```

## Testing Strategy

### Unit Tests
- Test metrics formatter with various cluster states
- Verify Prometheus format compliance
- Test error handling scenarios

### Integration Tests
- End-to-end metrics collection
- CMON scraping validation
- Alert rule testing

### Load Testing
- High-frequency scraping impact
- Concurrent scrape handling
- Memory usage analysis

## Rollout Strategy

### Development
1. Implement in development branch
2. Test with synthetic cluster data
3. Validate format with Prometheus

### Staging
1. Deploy to staging Manatee clusters
2. Configure CMON monitoring
3. Test alerting and dashboards

### Production
1. Rolling deployment to production
2. Monitor for performance impact
3. Gradual enablement of alerting

## Success Metrics

- [ ] All Manatee clusters expose metrics endpoint
- [ ] CMON successfully scrapes all instances
- [ ] Alert rules fire correctly for test scenarios
- [ ] No performance degradation observed
- [ ] Operational teams report improved visibility
